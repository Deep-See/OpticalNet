<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>	
    OpticalNetüî¨</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-LJG41FLB28"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-LJG41FLB28'); </script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">	
              OpticalNetüî¨: An Optical Imaging Dataset and Benchmark Beyond the Diffraction Limit</h1>
            <!-- <div style="display: flex; justify-content: center; align-items: center; margin-left: -40px;">
                <h1 style="margin: 0;">OpticalNet</h1>
            </div>
            <h2>An Optical Imaging Dataset and Benchmark
               Beyond the Diffraction Limit</h2> -->
            <pitalic>üîçSeeing and Building your own LEGOüß©at Subwavelength</pitalic> <br>
            <br>
            <pbold>CVPR 2025</pbold>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sg.linkedin.com/in/benquan-w-a677161a2" target="_blank">Benquan Wang</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://ruyianry.github.io" target="_blank">Ruyi An</a><sup>4*</sup>,</span><br>
              <span class="author-block">
                <a href="https://scholar.google.co.uk/citations?user=EOlkdT8AAAAJ&hl=en" target="_blank">Jin-Kyu So</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://nanophotonics.org.uk/niz/people/Kurdiumov_S.php" target="_blank">Sergei Kurdiumov</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com.sg/citations?user=COuBynYAAAAJ&hl=en" target="_blank">Eng Aik Chan</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com.sg/citations?user=Aw-HKdcAAAAJ&hl=en" target="_blank">Giorgio Adamo</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/yuhan0524/" target="_blank">Yuhan Peng</a><sup>1</sup>,
              </span><br>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=W5796yEAAAAJ&hl=zh-CN" target="_blank">Yewen Li</a><sup>1&#8224</sup>,
              </span>
              <span class="author-block">
                <a href="https://personal.ntu.edu.sg/boan/" target="_blank">Bo An</a><sup>1</sup>
              </span>


              </div>

              <div class="is-size-6 publication-authors">
                <span class="author-block">(* equal contributions, &#8224 corresponding author) </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>Nanyang Technological University<br></span>,
                <span class="author-block"><sup>2</sup>Skywork AI, Singapore<br></span>,
                <span class="author-block"><sup>3</sup>University of Southampton<br></span>,
                <span class="author-block"><sup>4</sup>The University of Texas at Austin<br></span>
                <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
              </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="assets/paper.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="assets/paper.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Deep-See/OpticalNet" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                            <!-- Huggingface Demo Link. -->
            <span class="link-block">
              <a href="https://huggingface.co/datasets/Deep-See/OpticalNet" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <img src="assets/hf-logo.svg" style="display:block;width:330px;height:240px" />
                </span>
                <span>Dataset</span>
              </a>
            </span>

              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="assets/images/teaser.svg" style="width: 100%; height: auto;" />

      <!-- <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video> -->
      <h2 class="subtitle has-text-centered">
        <b>Framework of OpticalNet</b> 
      </h2>
      <p class="subtitle has-text-justified">
        Drawing an analogy to modular construction in LEGO, where small unitsüß©could be assembled to create larger complex objectsüß±, we build the OpticalNet dataset that deconstructs arbitrary-shaped objects into basic building blocks‚Äîsmall <span>\(n \times n\)</span> grid regions consisting of squares with sizes below the diffraction limit. This dataset is collected through microscopy imaging via sample scanning, and we can train a deep-learning-based model to predict object images using diffraction images as inputs. With the trained model, we translate diffraction images of complex-shaped objects into their corresponding object images for each spatial position and assemble these modular predictions accordingly to reconstruct the complete structures, enabling subwavelength imaging beyond the diffraction limit.
      </p>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Optical imaging capable of resolving nanoscale features would revolutionize scientific research and engineering applications across biomedicine, smart manufacturing, and semiconductor quality control. However, due to the physical phenomenon of diffraction, the optical resolution is limited to approximately half the wavelength of light, which impedes the observation of subwavelength objects such as the native state coronavirus, typically smaller than 200 nm. Fortunately, deep learning methods have shown remarkable potential in uncovering underlying patterns within data, promising to overcome the diffraction limit by revealing the mapping pattern between diffraction images and their corresponding ground truth object images. However, the absence of suitable datasets has hindered progress in this field--collecting high-quality optical data of subwavelength objects is highly difficult as these objects are inherently invisible under conventional microscopy, making it impossible to perform standard visual calibration and drift correction. Therefore, we provide the first general optical imaging dataset based on the ‚Äúbuilding block‚Äù concept for challenging the diffraction limit. Drawing an analogy to modular construction principles, we construct a comprehensive optical imaging dataset comprising subwavelength fundamental elements, i.e., small square units that can be assembled into larger and more complex objects. We then frame the task as an image-to-image translation task and evaluate various vision methods. Experimental results validate our ‚Äúbuilding block‚Äù concept, demonstrating that models trained on basic square units can effectively generalize to realistic, more complex unseen objects. Most importantly, by highlighting this underexplored AI-for-science area and its potential, we aspire to advance optical science by fostering collaboration with the vision and machine learning communities.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="image-comparison-container">
  <div class="image-comparison-content">
    <div class="slider" style="left: 50%;"></div>
      <img src="assets/images/transformer_online_colorized.png" alt="Image 1" class="image-1"/>
      <img src="assets/images/ORC_colorized.png" alt="Image 2" class="image-2" style="clip-path: inset(0 0 0 50%);"/>
  </div>
  <div class="captions has-text-centered">
    <span class="caption-text">Slide left or right</span>
  </div>
  <script src="static/js/image-comparison.js"></script>
</section>



<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title" style="font-size: 1.125rem;">If you use OpticalNet or find find our work inspiring in your research, please cite us:</h2>
      <pre class="bibtex-pre"><code><span class="bibtex-type">@inproceedings</span>{wang2025optical,<br>
  <span class="bibtex-keyword">title</span>={<span class="bibtex-value">OpticalNet: An Optical Imaging Dataset and Benchmark Beyond the Diffraction Limit</span>},<br>
  <span class="bibtex-keyword">author</span>={<span class="bibtex-value">Wang, Benquan and An, Ruyi, and So, Jin-Kyu and Kurdiumov, Sergei and Chan, Eng Aik and Adamo, Giorgio and Peng, Yuhan and Li, Yewen and An, Bo</span>},<br>
  <span class="bibtex-keyword">booktitle</span>={<span class="bibtex-value">CVPR</span>},<br>
  <span class="bibtex-keyword">year</span>={<span class="bibtex-value">2025</span>}<br>
}</code></pre><br>
      </pre>
    </div>
</section>
<!--End BibTex citation -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
